{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 경로\n",
    "\n",
    "data_path = './porto-seguro-safe-driver-prediction/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv' , index_col = 'id')\n",
    "test = pd.read_csv(data_path + 'test.csv' , index_col = 'id')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv' , index_col ='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n0                2              2          5              1              0   \n1                1              1          7              0              0   \n2                5              4          9              1              0   \n3                0              1          2              0              0   \n4                0              2          0              1              0   \n...            ...            ...        ...            ...            ...   \n1488023          0              1          6              0              0   \n1488024          5              3          5              1              0   \n1488025          0              1          5              0              0   \n1488026          6              1          5              1              0   \n1488027          7              1          4              1              0   \n\n         ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n0                    0              1              0              0   \n1                    0              0              1              0   \n2                    0              0              1              0   \n3                    1              0              0              0   \n4                    1              0              0              0   \n...                ...            ...            ...            ...   \n1488023              0              1              0              0   \n1488024              0              0              1              0   \n1488025              1              0              0              0   \n1488026              0              0              0              1   \n1488027              0              0              0              1   \n\n         ps_ind_10_bin  ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n0                    0  ...           9           1           5           8   \n1                    0  ...           3           1           1           9   \n2                    0  ...           4           2           7           7   \n3                    0  ...           2           2           4           9   \n4                    0  ...           3           1           1           3   \n...                ...  ...         ...         ...         ...         ...   \n1488023              0  ...           4           2           3           4   \n1488024              0  ...           6           2           2          11   \n1488025              0  ...           5           2           2          11   \n1488026              0  ...           1           1           2           7   \n1488027              0  ...           5           2           2           7   \n\n         ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n0                     0               1               1               0   \n1                     0               1               1               0   \n2                     0               1               1               0   \n3                     0               0               0               0   \n4                     0               0               0               1   \n...                 ...             ...             ...             ...   \n1488023               0               1               0               0   \n1488024               0               0               1               1   \n1488025               0               1               1               0   \n1488026               1               1               0               0   \n1488027               0               1               1               1   \n\n         ps_calc_19_bin  ps_calc_20_bin  \n0                     0               1  \n1                     1               0  \n2                     1               0  \n3                     0               0  \n4                     1               0  \n...                 ...             ...  \n1488023               1               0  \n1488024               0               0  \n1488025               0               0  \n1488026               0               0  \n1488027               0               0  \n\n[1488028 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ps_ind_01</th>\n      <th>ps_ind_02_cat</th>\n      <th>ps_ind_03</th>\n      <th>ps_ind_04_cat</th>\n      <th>ps_ind_05_cat</th>\n      <th>ps_ind_06_bin</th>\n      <th>ps_ind_07_bin</th>\n      <th>ps_ind_08_bin</th>\n      <th>ps_ind_09_bin</th>\n      <th>ps_ind_10_bin</th>\n      <th>...</th>\n      <th>ps_calc_11</th>\n      <th>ps_calc_12</th>\n      <th>ps_calc_13</th>\n      <th>ps_calc_14</th>\n      <th>ps_calc_15_bin</th>\n      <th>ps_calc_16_bin</th>\n      <th>ps_calc_17_bin</th>\n      <th>ps_calc_18_bin</th>\n      <th>ps_calc_19_bin</th>\n      <th>ps_calc_20_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1488023</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1488024</th>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1488025</th>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1488026</th>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1488027</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1488028 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train , test] , ignore_index= True)\n",
    "all_data = all_data.drop('target' , axis = 1) # 타깃값 제거\n",
    "\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n       'ps_calc_20_bin'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = all_data.columns # 전체 피처\n",
    "all_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 명목형 피처 원-핫 인코딩"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<1488028x184 sparse matrix of type '<class 'numpy.float64'>'\n\twith 20832392 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 명목형 피처 추출\n",
    "cat_features = [feature for feature in all_features if 'cat' in feature]\n",
    "# 이름에 cat이 포함된 피처가 명목형 피처이다.\n",
    "onehot_encoder = OneHotEncoder() # 원-핫 인코더 객체 생성\n",
    "\n",
    "# 인코딩\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\n",
    "\n",
    "encoded_cat_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 추가로 제거할 피처\n",
    "drop_features = ['ps_ind14' , 'ps_ind_10_bin' , 'ps_ind_11_bin' , 'ps_ind_12_bin' , 'ps_ind_13_bin' , 'ps_car_14' ]\n",
    "\n",
    "# 1> 명목형 피처 , 2> calc 분류의 피처 , 3> 추가 제거할 피처를 제외한 피처\n",
    "\n",
    "remaining_features = [feature for feature in all_features\n",
    "                      if ('cat' not in feature and\n",
    "                          'calc' not in feature and\n",
    "                          feature not in drop_features)]\n",
    "# cat(명목형) 피처 , calc(피처) , 추가 제거할 6개피처를 제외한 나머지 피처를 remaining_features 에 저장"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<1488028x202 sparse matrix of type '<class 'numpy.float64'>'\n\twith 37644877 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data[remaining_features]) , encoded_cat_matrix] , format= 'csr')\n",
    "\n",
    "all_data_sprs\n",
    "\n",
    "# CSR  형식으로 바꾸어 hstack()으로 행렬을 수평 방향으로 합친다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X = all_data_sprs[:num_train]\n",
    "X_test = all_data_sprs[num_train :]\n",
    "\n",
    "y = train['target'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 지니계수"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 지니계수란?\n",
    "\n",
    "# 소득 불평등 정도를 나타내는 지표. 지니계수가 작을수록 소득 수준이 평등하고, 클수록 불평등함을 의미한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 정규화 지니계수 계산 함수\n",
    "\n",
    "# 정규화란 값의 범위를 0~1 사이로 조정한다는 의미, 정규화 지니계수는 값이 0에 가까울수록 성능이 나쁘고, 1에 가까울 수록 성능이 좋다는 의미가 된다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def eval_gini(y_true , y_pred):\n",
    "    # 실제값과 예측값의 크기가 서로 같은지 확인(값이 다르면 오류 발생)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    n_samples = y_true.shape[0] # 데이터 개수\n",
    "    L_mid = np.linspace(1/ n_samples ,1 , n_samples) # 대각선 값\n",
    "\n",
    "    # 1) 예측값에 대한 지니계수\n",
    "\n",
    "    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
    "\n",
    "    G_pred = np.sum(L_mid - L_pred) # 예측값에 대한 지니계수\n",
    "\n",
    "    # 2) 예측이 완벽할 때 지니계수\n",
    "\n",
    "    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n",
    "    G_true = np.sum(L_mid - L_true) # 예측이 완벽할 때 지니계수\n",
    "\n",
    "    # 정규화된 지니계수\n",
    "    return G_pred / G_true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM 용 gini() 함수\n",
    "\n",
    "def gini(preds , dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "\n",
    "    return 'gini' , eval_gini(labels , preds ) , True\n",
    "\n",
    "# 'gini' : 평가지표이름 , eval_gini(labels,preds) : 평가점수 , True : 평가 점수가 높을수록 좋은지 여부"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 훈련 및 성능 검증"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OOF(Out of Fold prediction) 예측 방식\n",
    "\n",
    "# K 폴드 교차 검증을 수행하면서 각 폴드마다 테스트 데이터로 예측하는 방식이다.\n",
    "\n",
    "# K 폴드 교차 검ㅈ응을 하면서 폴드마다 1> 훈련 데이터로 모델을 훈련하고, 2> 검증 데이터로 모델 성능을 측정하며 , 3> 테스트 데이터로 최종 타깃 확률도 예측한다. 훈련된 모델로 마지막에 한 번만 예측하는 것이 아니다. 각 폴드별 모델로 여러번 예측해 평균을 내는 방식이다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OOF 방식으로 LightGBM 훈련\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기\n",
    "\n",
    "folds = StratifiedKFold(n_splits= 5 , shuffle= True , random_state= 1991)\n",
    "\n",
    "# 층화 K 폴드 교차 검증기는 타깃값이 불균형하므로 K폴드가 아닌 층화 K폴드를 수행하는 게 바람직하다. 층화 K폴드는 타깃값이 균등하게\n",
    "# 폴드를 나누는 방식이기 때문이다.\n",
    "\n",
    "\n",
    "# n_splits 파라미터로 전달한 수만큼 폴드를 나눈다. 여기서는 5개로 나누었다. shuffle = True 를 전달하면 폴드를 나눌때 데이터를 섞어준다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM의 하이퍼파라미터를 설정한다. LightGBM은 하이퍼파라미터를 갖고 있지만, 여기서는 4가지만 설정한다.\n",
    "\n",
    "params = {'objective' : 'binary' , 'learning_rate' : 0.01 , 'force_row_wise' : True , 'random_state' : 0}\n",
    "\n",
    "# 이진분류 문제이므로 objective 파라미터는 binary로 설정했다. 학습률은 0.01로, 랜덤 스테이트 값은 9으로 설정했다.\n",
    "# force_row_wise : True 는 경고 문구를 없애려고 추가한 파라미터이다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds = np.zeros(X.shape[0])\n",
    "\n",
    "# ==> oof_val_preds 는 검증 데이터를 활용해 예측한 확률값을 저장하는 배열이다. K 폴드로 나누어도 훈련 데이터 전체가 결국엔 한 번씩 검증 데이터로 활용된다. 따라서 oof_val_preds 배열 크기는 훈련 데이터와 같아야 한다.\n",
    "# 훈련 데이터 개수는 X.shpae[0]으로 구한다.\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# oof_test_preds는 테스트 데이터를 활용해 예측한 확률값을 저장하는 배열이다. 최종 제출에 사용할 값이므로 크기는 테스트 데이터와 같아야한다. 테스트 데이터 개수는 X_test.shape[0]으로 구한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org lightgbm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# OOF 방식으로 모델 훈련 , 검증 , 예측\n",
    "\n",
    "for idx, (train_idx , valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40 , f'폴드 {idx +1} / 폴드 {folds.n_splits}' , '#'*40)\n",
    "\n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train , y_train = X[train_idx] , y[train_idx] # 훈련용 데이터\n",
    "    X_valid , y_valid = X[valid_idx] , y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train , y_train) # LightGBM 전용 훈련 데이터 셋\n",
    "    dvalid = lgb.Dataset(X_valid , y_valid) # LightGBM 전용 검증 데이터 셋\n",
    "\n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params = params , # 훈련용 하이퍼파라미터\n",
    "                          train_set = dtrain, # 훈련 데이터 셋\n",
    "                          num_boost_round = 1000, # 부스팅 반복 횟수\n",
    "                          valid_sets=  dvalid ,  # 성능 평가용 검증 데이터 셋\n",
    "                          feval = gini, # 검증용 평가지표\n",
    "                          early_stopping_rounds = 100, # 조기종료 조건\n",
    "                          verbose_eval = 100 ) # 100번째마다 점수 출력\n",
    "\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "\n",
    "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
    "\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
    "\n",
    "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
    "\n",
    "    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
    "\n",
    "    gini_score = eval_gini(y_valid , oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx +1} 지니계수 : {gini_score}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('OOF 검증 데이터 지니계수 : ' , eval_gini(y , oof_val_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 성능 개선"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data = pd.concat([train , test] , ignore_index = True)\n",
    "all_data = all_data.drop('target' , axis =1 ) # 타깃값 제거\n",
    "\n",
    "all_features = all_data.columns # 전체 피처\n",
    "\n",
    "all_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 명목형 피처\n",
    "\n",
    "cat_features = [feature for feature in all_features if 'cat' in feature]\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 파생 피처 추가"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 탐색적 데이터 분석과정에서는 필요 없는 피처를 추리는 것 외에 특별한 피처 엔지니어링 건을 찾아내지 못했다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 첫번째 , 한 데이터가 가진 결측값 개수를 파생 피처로 만들어본다. -1 이 결측값이므로 결측값 개수를 구하려면 -1 개수를 구하면 된다.\n",
    "\n",
    "# 데이터 하나당 결측값 개수를 파생 피처로 추가\n",
    "\n",
    "all_data['num_missing'] = (all_data == -1).sum(axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 명목형 피처 , calc 분류의 피처를 제외한 피처\n",
    "\n",
    "remaining_features = [feature for feature in all_features if ('cat' not in feature and 'calc' not in feature)]\n",
    "\n",
    "# num_missing을 remaining_features 에 추가\n",
    "\n",
    "remaining_features.append('num_missing')\n",
    "\n",
    "remaining_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 두번째, ind 분류의 피처들을 살펴본다. 모든 ind 피처 값을 연결해서 새로운 피처를 만들려고한다.\n",
    "\n",
    "# 예를들어 , ps_ind_01 , ps_ind_02_car , ps_ind_03의 값이 각각 2, 3, 5 라면 모든 값을 연결해 2_2_5_로 만든다.\n",
    "\n",
    "# ind 피처가 총 18개이므로 18개 값이 연결된다.\n",
    "\n",
    "ind_features = [feature for feature in all_features if 'ind' in feature]\n",
    "\n",
    "is_first_feature = True\n",
    "\n",
    "for ind_feature in ind_features:\n",
    "    if is_first_feature:\n",
    "        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '-'\n",
    "        is_first_feature = False\n",
    "    else:\n",
    "        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '-'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['mix_ind']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 세번째 , 명목형 피처의 고윳값별 개수를 새로운 피처로 추가한다. 고윳값별 개수는 value_counts()로 구한다.\n",
    "\n",
    "# ps_ind_02_cat 피처의 고윳값별 개수 코드\n",
    "\n",
    "all_data['ps_ind_02_cat'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 명목형 피처의 고윳값별 개수를 파생 피처로 생성\n",
    "all_data['ps_ind_02_cat'].value_counts().to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_count_features = []\n",
    "\n",
    "for feature in cat_features+['mix_ind']:\n",
    "    val_counts_dict = all_data[feature].value_counts().to_dict()\n",
    "    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: val_counts_dict[x])\n",
    "\n",
    "    cat_count_features.append(f'{feature}_count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_count_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# 필요 없는 피처들\n",
    "drop_features = ['ps_ind_14' , 'ps_ind_10_bin' , 'ps_ind_11_bin' , 'ps_ind_12_bin' , 'ps_ind_13_bin' , 'ps_car_14']\n",
    "\n",
    "# remaining_features , cat_count_features 에서 drop_features를 제거한 데이터\n",
    "\n",
    "all_data_remaining = all_data[remaining_features + cat_count_features].drop(drop_features , axis = 1)\n",
    "\n",
    "# 데이터 합치기\n",
    "\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining) , encoded_cat_matrix] ,format = 'csr')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 나누기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X = all_data_sprs[:num_train]\n",
    "X_test = all_data_sprs[num_train :]\n",
    "\n",
    "y = train['target'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 하이퍼파라미터 최적화"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2 비율로 훈련 데이터, 검증 데이터 분리(베이지안 최적화 수행용)\n",
    "\n",
    "X_train , X_valid , y_train , y_valid = train_test_split(X,y, test_size=0.2 , random_state=0)\n",
    "\n",
    "# 베이지안 최적화용 데이터셋\n",
    "\n",
    "bayes_dtrain = lgb.Dataset(X_train , y_train)\n",
    "bayes_dvalid = lgb.Dataset(X_valid, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
    "param_bounds = {'num_leaves' : (30 , 40) , # 개별 트리가 가질 수 있는 최대 말단 노드 개수 , 트리 복잡도 결정, 값이 클수록 좋다.\n",
    "                'lambda_l1' : (0.7 , 0.9), # L1 규제 조정값 , 값이 클수록 과대적합 방지 효과\n",
    "                'lambda_l2' : (0.9 , 1), # L2 규제 조정값 , 값이 클수록 과대적합 방지 효과\n",
    "                'feature_fraction' : (0.6 , 0.7), # 개별 트리를 훈련할 때 사용할 피처 샘플링 비율\n",
    "                'bagging_fraction' : (0.6 , 0.9), # 개별 트리를 훈련할 때 사용할 데이터 샘플링 비율\n",
    "                'min_child_samples' : (6 , 10) , # 말단 노드가 되기 위해 필요한 최소 데이터 개수 , 값이 클수록 과대적합 방지\n",
    "                'min_child_weight' : (10 , 40)} # 과대적합 방지 위한 값\n",
    "\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터\n",
    "\n",
    "fixed_params = {'objective' : 'binary' , # 훈련 목적 , 회귀에서는 'regression' , 이진분류에서는 'binary' , 다중분류에서는 'multiclass' 사용\n",
    "                'learning_rate' : 0.005, # 학습률( 부스팅 이터레이션을 반복하면서 모델을 업데이트하는 데 사용 되는 비율)\n",
    "                'bagging_freq' : 1, # 배깅 수행 빈도, 몇번의 이터레이션마다 배깅 수행할 지 결정\n",
    "                'force_row_wise' : True, # 메모리 용량이 충분하지 않을 때 메모리 효율을 높이는 파라미터\n",
    "                'random_state' : 1991} # 랜덤 시드값 (코드를 반복 실행해도 같은 결과가 나오게 지정하는 값)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 베이지안 최적화용 평가지표 계산 함수 작성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_function(num_leaves , lambda_l1 , lambda_l2 , feature_fraction , bagging_fraction , min_child_samples , min_child_weight) :\n",
    "\n",
    "# 최적화하려는 평가지표(지니계수) 계산 함수\n",
    "\n",
    "# 베이지안 최적화를 수행할 하이퍼파라미터\n",
    "\n",
    "    params = {'num_leaves' : int(round(num_leaves)) , # 개발 트리가 가질 수 있는 최대 말단 노드 개수, 트리 복잡도 결정 , 값이 클수록 좋다.\n",
    "              'lambda_l1' : lambda_l1, # L1 규제 조정값 , 값이 클 수록 과대적합 방지 효과\n",
    "              'lambda_l2' : lambda_l2 , # L2 규제 조정값 , 값이 클 수록 과대적합 방지 효과\n",
    "              'feature_fraction' : feature_fraction ,  # 개별 트리를 훈련할 때 사용할 피처 샘플링 비율\n",
    "              'bagging_fraction' : bagging_fraction, # 개별 트리를 훈련할 때 사용할 배깅 데이터 샘플링 비율\n",
    "              'min_child_samples' : int(round(min_child_samples)) , # 말단 노드가 되기 위해 필요한 최소 데이터 개수, 값이 클수록 과대적합 방지\n",
    "              'min_child_weight' : min_child_weight, # 과대적합 방지 위한 값\n",
    "              'feature_pre_filter' : False} #\n",
    "\n",
    "    #하이퍼파라미터도 추가\n",
    "    params.update(fixed_params)\n",
    "\n",
    "    print('하이퍼파라미터 : ' , params)\n",
    "\n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params = params , # 훈련용 하이퍼파라미터\n",
    "                          train_set = bayes_dtrain, # 훈련 데이터셋\n",
    "                          num_boost_round= 2500, #부스팅 반복횟수\n",
    "                          valid_sets= bayes_dvalid, # 성능 평가용 검증 데이터 셋\n",
    "                          feval = gini, # 검증용 평가지표\n",
    "                          early_stopping_rounds= 300, # 조기종료 조건\n",
    "                          verbose_eval= False) # 계속 점수 출력\n",
    "    # 검증 데이터로 예측 수행\n",
    "    preds = lgb_model.predict(X_valid)\n",
    "\n",
    "    # 지니계수 계산\n",
    "    gini_score = eval_gini(y_valid, preds)\n",
    "    print(f'지니계수 : {gini_score}\\n')\n",
    "\n",
    "    return gini_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 최적화 수행"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org colorama==0.4.4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org bayesian-optimization==1.4.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "optimizer = BayesianOptimization(f = eval_function, # 평가지표 계산 함수\n",
    "                                pbounds = param_bounds, # 하이퍼파라미터 범위\n",
    "                                random_state = 0 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 베이지안 최적화 수행\n",
    "\n",
    "optimizer.maximize(init_points=  3 , n_iter = 6) # init_points 는 무작위로 하이퍼파라미터를 탐색하는 횟수, n_iter는 베이지안 최적화 반복 횟수"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 결과확인"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 평가함수 점수가 최대일 대 하이퍼파라미터\n",
    "max_params = optimizer.max['params']\n",
    "max_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 정수형 하이퍼파라미터 변환\n",
    "\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 값이 고정된 하이퍼파라미터 추가\n",
    "\n",
    "max_params.update(fixed_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 최종 하이퍼파라미터 출력\n",
    "max_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 훈련 및 성능 검증"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기 생성\n",
    "folds = StratifiedKFold(n_splits=5 , shuffle = True , random_state= 1991)\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "\n",
    "oof_val_preds = np.zeros(X.shape[0])\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# OOF 방식으로 모델 훈련 ,검증 , 예측\n",
    "\n",
    "for idx, (train , valid_idx) in enumerate(folds.split(X,y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40 , f'폴드 {idx+1} / 폴드 {folds.n_splits}' , '#'*40)\n",
    "\n",
    "    X_train , y_train = X[train_idx] , y[train_idx] # 훈련용 데이터\n",
    "    X_valid , y_valid = X[valid_idx] , y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train , y_train) # LightGBM 전용 훈련 데이터셋\n",
    "    dvalid = lgb.Dataset(X_valid , y_valid) # LightGBM 전용 검증 데이터셋\n",
    "\n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params = max_params , # 최적 하이퍼파라미터\n",
    "                          train_set = dtrain, # 훈련 데이터 셋\n",
    "                          num_boost_round= 2500, # 부스팅 반복 횟수\n",
    "                          valid_sets= dvalid , # 성능 평가용 검증 데이터셋\n",
    "                          feval = gini, # 검증용 평가지표\n",
    "                          early_stopping_rounds= 300, # 조기종료 조건\n",
    "                          verbose_eval = 100) # 100 번째 마다 점수 출력\n",
    "\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds += lgb_model.predict(X_test) / folds.n_splits\n",
    "\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
    "\n",
    "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
    "    oof_test_preds_lgb = oof_test_preds\n",
    "    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
    "    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx+1}  지니계수 : {gini_score}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oof_val_preds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('OOF 검증 데이터 지니계수 :' , eval_gini(y, oof_val_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost 피처 엔지니어링"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM 용 gini() 함수\n",
    "def gini(preds , dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini' , eval_gini(labels , preds) , True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# XGBoost용 gini() 함수\n",
    "\n",
    "def gini(preds , dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini' , eval_gini(labels,preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 하이퍼파라미터 최적화"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 셋 준비"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2 비율로 훈련 데이터 , 검증 데이터 분리( 베이지안 최적화 수행용)\n",
    "\n",
    "X_train , X_valid , y_train , y_valid = train_test_split(X,y, test_size=0.2 , random_state=0)\n",
    "\n",
    "# 베이지안 최적화용 데이터셋\n",
    "\n",
    "bayes_dtrain = xgb.DMatrix(X_train , y_train)\n",
    "bayes_dvalid = xgb.DMatrix(X_valid, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 하이퍼파라미터 범위 설정"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
    "param_bounds = {'max_depth' : (4 , 8) , # 개별 트리의 최대 깊이, 트리 깊이가 깊을수록 모델이 복잡해지고 과대적합 우려\n",
    "                # 값이 클수록 깊이가 한 단계만 늘어나도 메모리 사용량이 급격히 많아진다.\n",
    "                # 일반적으로 3~10 사이의 값을 주로 사용한다.\n",
    "\n",
    "                'subsample' : (0.6 , 0.9), # 개별 트리를 훈련할 때 사용할 데이터 샘플링 비율\n",
    "                # 0~1 사이 값으로 설정할 수 있다.\n",
    "                # 0.5 로 설정하면 전체 데이터의 50%를 사용해 트리를 생성\n",
    "\n",
    "                'colsample_bytree' : (0.7 , 1.0), # 개별 트리를 훈련할 때 사용하는 피처 샘플링 비율\n",
    "                # subsample 과 유사한 개념, subsample은 전체 데이터에서 얼마나 샘플링할지 나타내는 비율\n",
    "                # colsample_bytree는 전체 피처에서 얼마나 샘플링할지 나타내는 비율\n",
    "                # 값이 작을수록 과대적합 방지 효과\n",
    "\n",
    "                'min_child_weight' : (5 , 7), # 과대적합 방지위한 값, 값이 클수록 과대적합 방지 효과가 있다.\n",
    "                'gamma' : (8 , 11), # 말단 노드가 분할하기 위한 최소 손실 감소 값\n",
    "                # 소실 감소가 gamma보다 크면 말단 노드를 분할\n",
    "                # 값이 클수록 과대적합 방지 효과가 있다.\n",
    "\n",
    "                'reg_alpha' : (7 , 9) , # L1 규제 조정 값 , 값이 클수록 과대적합 방지 효과\n",
    "                'reg_lambda' : (1.1 , 1.5), # L2 규제 조정값 , 값이 클수록 과대적합 방지 효과\n",
    "                'scale_pos_weight' : (1.4 , 1.6)} # 뷸균형 데이터 가중치 조정 값 ,\n",
    "                # 타깃값이 불균형할 때 양성 값에 scale_pos_weight 만큼 가중치를 줘서 균형을 맞춤(타깃값 1을 양성 값으로 간주)\n",
    "                # 일반적으로 scale_pos_weight 값을 (음성 타깃값 개수 / 양성 타깃값 개수) 로 설정\n",
    "\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터\n",
    "\n",
    "fixed_params = {'objective' : 'binary:logistic' ,# 훈련 목적 , binary : logistic( 확률값을 구하는 이진분류)\n",
    "                # reg : squarederror (회귀 문제)\n",
    "                # 소프트맥스 함수를 사용하는 다중분류에서는 multi : softmax 사용\n",
    "                # 확률값을 구하는 다중분류에서는 'multi : softprob' 사용\n",
    "                'learning_rate' : 0.02, # 학습률( 부스팅 스텝을 반복하면서 모델을 업데이트하는 데 사용되는 비율)\n",
    "                'random_state' : 1991} # 랜덤 시드값(코드를 반복 실행해도 같은 결과가 나오게 지정하는 값)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_function(max_depth , subsample , colsample_bytree , min_child_weight , reg_alpha , gamma , reg_lambda , scale_pos_weight) :\n",
    "\n",
    "    # 최적화하려는 평가지표(지니계수) 계산 함수\n",
    "\n",
    "    # 베이지안 최적화를 수행할 하이퍼파라미터\n",
    "\n",
    "    params = {'max_depth' : int(round(max_depth)) , # 개별 트리의 최대깊이\n",
    "              'subsample' : subsample, # 개별 트리를 훈련할 때 사용할 데이터 샘플링 비율\n",
    "              'colsample_bytree' : colsample_bytree , # 개별 트리를 훈련할때 사용하는 피처 샘플링\n",
    "              'min_child_weight' :  # 과대적합 방지위한 값\n",
    "              min_child_weight,\n",
    "              'gamma' : gamma, # 말단 노드가 분할하기 위한 최소 손실 감소 값\n",
    "              'reg_alpha' : reg_alpha, # L1 규제 조정값\n",
    "              'reg_lambda' : reg_lambda, # L2 규제 조정값\n",
    "              'scale_pos_weight' : scale_pos_weight} # 불균형 데이터 가중치 조정값\n",
    "\n",
    "    # 값이 고정된 하이퍼파라미터도 추가\n",
    "    params.update(fixed_params)\n",
    "\n",
    "    print('하이퍼파라미터 : ' , params)\n",
    "\n",
    "    # XGBoost 모델 훈련 , train() 메서드의 하이퍼파라미터\n",
    "    xgb_model = xgb.train(params = params , # XGBoost 모델의 하이퍼파라미터 목록 , 딕셔너리 타입으로 전달\n",
    "                          dtrain = bayes_dtrain, # 훈련 데이터셋, xgboost.DMatrix 타입으로 전달\n",
    "                          num_boost_round= 2000, # 부스팅 반복 횟수, 정수형 타입으로 전달\n",
    "                          # num_boost_round 값이 클수록 성능이 좋아질 수 있으나 과대적합의 우려가 있다.\n",
    "                          # num_boost_round 값이 작으면 반복 횟수가 줄어들어 훈련 시간이 짧아진다.\n",
    "                          # 일반적으로 num_boost_round를 늘리면 learning_rate를 줄여야 한다.\n",
    "\n",
    "                          evals = [(bayes_dvalid , ' bayes_dvalid')],\n",
    "                          # 모델 성능 평가용 검증 데이터셋\n",
    "                          # (DMatrix, 문자열) 쌍들을 원소로 갖는 리스트 타입으로 전달, 검증 데이터셋 이름을 원하는 대로 문자열로 정하면 된다.\n",
    "                          maximize = True, # feval 평가지수가 높으면 좋은지 여부\n",
    "                          feval = gini, # 검증용 평가지표, 사용자 정의 함수 형태\n",
    "                          # evals를 활용해 모델 성능을 검증할 때 사용할 사용자 정의 평가지표 함수\n",
    "                          # 예측값과 실제값을 파라미터로 전달받아, 평가지표명과 평가점수를 반환하는 함수이다.\n",
    "                          early_stopping_rounds= 200,\n",
    "                          # 조기종료 조건\n",
    "                          # 모델은 기본적으로 num_boost_round만큼 훈련을 반복하며, 매 이터레이션마다 evals로 모델 성능을 평가하여 성능이 연속으로\n",
    "                          # 좋아지지 않는다면 훈련을 중단하는데, 훈련 중단에 필요한 최소횟수가 early_stopping_rounds 이다. 즉 , early_stopping_rounds\n",
    "                          # 동안 모델 성능이 좋아지지 않는다면 훈련을 중단한다.\n",
    "\n",
    "                          # 과대적합 방지 효과\n",
    "\n",
    "                          # 조기종료를 적용하기 위해서는 evals 에 검증 데이터가 하나 이상 있어야한다. 또한 evals에 검증 데이터가 여러 개라면 마지막 검증\n",
    "                          # 데이터를 기준으로 조기종료 조건을 적용한다.\n",
    "\n",
    "\n",
    "                          verbose_eval= False) # 성능 점수 로그 설정 값\n",
    "                            # True 로 설정하면 매 부스팅 스텝마다 평가점수르 출력\n",
    "                            # 출력값이 너무 많아지는 것을 방지하기위해 verbose_eval로 설정\n",
    "\n",
    "    best_iter = xgb_model.best_iteration # 최적 반복횟수\n",
    "    # 검증 데이터로 예측 수행\n",
    "    preds = xgb_model.predict(bayes_dvalid , iteration_range=(0, best_iter))\n",
    "\n",
    "    # 지니계수 계산\n",
    "    gini_score = eval_gini(y_valid, preds)\n",
    "    print(f'지니계수 : {gini_score}\\n')\n",
    "\n",
    "    return gini_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 최적화 수행"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "\n",
    "optimizer = BayesianOptimization(f= eval_function, pbounds = param_bounds , random_state= 0)\n",
    "\n",
    "\n",
    "# 베이지안 최적화 수행\n",
    "\n",
    "\n",
    "optimizer.maximize(init_points= 3 , n_iter= 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 결과확인"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
    "max_params = optimizer.max['params']\n",
    "max_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 정수형 하이퍼파라미터 변환\n",
    "\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터 추가\n",
    "\n",
    "max_params.update(fixed_params)\n",
    "max_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 훈련 및 성능 검증"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기 생성\n",
    "folds = StratifiedKFold(n_splits= 5 , shuffle= True , random_state= 1991)\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds = np.zeros(X.shape[0])\n",
    "\n",
    "# OOF 방식으로 훈련된 모델 훈련 , 검증 , 예측\n",
    "\n",
    "for idx , (train_idx , valid_idx) in enumerate(folds.split(X,y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "\n",
    "    print('#' *40,  f'폴드 {idx+1} / 폴드 {folds.n_splits}' , '#'*40)\n",
    "\n",
    "\n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train , y_train = X[train_idx] , y[train_idx]\n",
    "    X_valid , y_valid = X[valid_idx] , y[valid_idx]\n",
    "\n",
    "    #XGBoost 전용 데이터셋 생성\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train , y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid , y_valid)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    #XGBoost 모델 훈련\n",
    "    xgb_model = xgb.train(params = max_params,\n",
    "                          dtrain = dtrain,\n",
    "                          num_boost_round = 2000,\n",
    "                          evals = [(dvalid , 'valid')],\n",
    "                          maximize = True,\n",
    "                          feval = gini,\n",
    "                          early_stopping_rounds = 200,\n",
    "                          verbose_eval = 100)\n",
    "\n",
    "    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n",
    "    best_iter= xgb_model.best_iteration\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "\n",
    "    oof_test_preds += xgb_model.predict(dtest, iteration_range = (0 , best_iter))/ folds.n_splits\n",
    "\n",
    "    oof_test_preds_xgb = oof_test_preds\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
    "    oof_val_preds[valid_idx] += xgb_model.predict(dvalid , iteration_range=(0, best_iter))\n",
    "\n",
    "\n",
    "    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
    "    gini_score = eval_gini(y_valid , oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx+1}  지니계수 : {gini_score}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oof_val_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 폴드 1 / 폴드 5 ########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyp\\anaconda3\\lib\\site-packages\\xgboost\\training.py:39: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-logloss:0.67671\tvalid-gini:0.16215\n",
      "[100]\tvalid-logloss:0.19182\tvalid-gini:0.24941\n",
      "[200]\tvalid-logloss:0.15837\tvalid-gini:0.27811\n",
      "[300]\tvalid-logloss:0.15506\tvalid-gini:0.28780\n",
      "[400]\tvalid-logloss:0.15452\tvalid-gini:0.29319\n",
      "[500]\tvalid-logloss:0.15439\tvalid-gini:0.29533\n",
      "[600]\tvalid-logloss:0.15433\tvalid-gini:0.29681\n",
      "[700]\tvalid-logloss:0.15427\tvalid-gini:0.29816\n",
      "[800]\tvalid-logloss:0.15425\tvalid-gini:0.29872\n",
      "[900]\tvalid-logloss:0.15422\tvalid-gini:0.29916\n",
      "[1000]\tvalid-logloss:0.15422\tvalid-gini:0.29949\n",
      "[1100]\tvalid-logloss:0.15422\tvalid-gini:0.29951\n",
      "[1200]\tvalid-logloss:0.15422\tvalid-gini:0.29941\n",
      "[1300]\tvalid-logloss:0.15420\tvalid-gini:0.29947\n",
      "[1337]\tvalid-logloss:0.15421\tvalid-gini:0.29944\n",
      "폴드 1  지니계수 : 0.2996383794197772\n",
      "\n",
      "######################################## 폴드 2 / 폴드 5 ########################################\n",
      "[0]\tvalid-logloss:0.67670\tvalid-gini:0.15338\n",
      "[100]\tvalid-logloss:0.19190\tvalid-gini:0.24056\n",
      "[200]\tvalid-logloss:0.15862\tvalid-gini:0.26445\n",
      "[300]\tvalid-logloss:0.15542\tvalid-gini:0.27408\n",
      "[400]\tvalid-logloss:0.15493\tvalid-gini:0.27824\n",
      "[500]\tvalid-logloss:0.15479\tvalid-gini:0.28058\n",
      "[600]\tvalid-logloss:0.15474\tvalid-gini:0.28193\n",
      "[700]\tvalid-logloss:0.15471\tvalid-gini:0.28279\n",
      "[800]\tvalid-logloss:0.15471\tvalid-gini:0.28313\n",
      "[900]\tvalid-logloss:0.15468\tvalid-gini:0.28360\n",
      "[1000]\tvalid-logloss:0.15467\tvalid-gini:0.28425\n",
      "[1100]\tvalid-logloss:0.15467\tvalid-gini:0.28435\n",
      "[1200]\tvalid-logloss:0.15465\tvalid-gini:0.28475\n",
      "[1300]\tvalid-logloss:0.15465\tvalid-gini:0.28490\n",
      "[1400]\tvalid-logloss:0.15464\tvalid-gini:0.28515\n",
      "[1500]\tvalid-logloss:0.15464\tvalid-gini:0.28503\n",
      "[1600]\tvalid-logloss:0.15465\tvalid-gini:0.28503\n",
      "[1635]\tvalid-logloss:0.15464\tvalid-gini:0.28506\n",
      "폴드 2  지니계수 : 0.2852264715520086\n",
      "\n",
      "######################################## 폴드 3 / 폴드 5 ########################################\n",
      "[0]\tvalid-logloss:0.67670\tvalid-gini:0.15662\n",
      "[100]\tvalid-logloss:0.19179\tvalid-gini:0.24702\n",
      "[200]\tvalid-logloss:0.15838\tvalid-gini:0.27073\n",
      "[300]\tvalid-logloss:0.15509\tvalid-gini:0.27895\n",
      "[400]\tvalid-logloss:0.15462\tvalid-gini:0.28197\n",
      "[500]\tvalid-logloss:0.15454\tvalid-gini:0.28295\n",
      "[600]\tvalid-logloss:0.15452\tvalid-gini:0.28350\n",
      "[700]\tvalid-logloss:0.15451\tvalid-gini:0.28375\n",
      "[800]\tvalid-logloss:0.15447\tvalid-gini:0.28444\n",
      "[900]\tvalid-logloss:0.15448\tvalid-gini:0.28427\n",
      "[1000]\tvalid-logloss:0.15448\tvalid-gini:0.28452\n",
      "[1100]\tvalid-logloss:0.15448\tvalid-gini:0.28462\n",
      "[1200]\tvalid-logloss:0.15448\tvalid-gini:0.28461\n",
      "[1300]\tvalid-logloss:0.15449\tvalid-gini:0.28438\n",
      "[1364]\tvalid-logloss:0.15447\tvalid-gini:0.28467\n",
      "폴드 3  지니계수 : 0.28469150190156506\n",
      "\n",
      "######################################## 폴드 4 / 폴드 5 ########################################\n",
      "[0]\tvalid-logloss:0.67670\tvalid-gini:0.16821\n",
      "[100]\tvalid-logloss:0.19173\tvalid-gini:0.23869\n",
      "[200]\tvalid-logloss:0.15846\tvalid-gini:0.26465\n",
      "[300]\tvalid-logloss:0.15526\tvalid-gini:0.27270\n",
      "[400]\tvalid-logloss:0.15482\tvalid-gini:0.27515\n",
      "[500]\tvalid-logloss:0.15472\tvalid-gini:0.27660\n",
      "[600]\tvalid-logloss:0.15467\tvalid-gini:0.27774\n",
      "[700]\tvalid-logloss:0.15464\tvalid-gini:0.27846\n",
      "[800]\tvalid-logloss:0.15462\tvalid-gini:0.27907\n",
      "[900]\tvalid-logloss:0.15461\tvalid-gini:0.27949\n",
      "[1000]\tvalid-logloss:0.15459\tvalid-gini:0.27973\n",
      "[1100]\tvalid-logloss:0.15460\tvalid-gini:0.27975\n",
      "[1200]\tvalid-logloss:0.15460\tvalid-gini:0.27984\n",
      "[1300]\tvalid-logloss:0.15460\tvalid-gini:0.27984\n",
      "[1400]\tvalid-logloss:0.15460\tvalid-gini:0.27981\n",
      "[1425]\tvalid-logloss:0.15461\tvalid-gini:0.27974\n",
      "폴드 4  지니계수 : 0.27991724318908323\n",
      "\n",
      "######################################## 폴드 5 / 폴드 5 ########################################\n",
      "[0]\tvalid-logloss:0.67671\tvalid-gini:0.17061\n",
      "[100]\tvalid-logloss:0.19185\tvalid-gini:0.24638\n",
      "[200]\tvalid-logloss:0.15860\tvalid-gini:0.27270\n",
      "[300]\tvalid-logloss:0.15535\tvalid-gini:0.28310\n",
      "[400]\tvalid-logloss:0.15484\tvalid-gini:0.28760\n",
      "[500]\tvalid-logloss:0.15469\tvalid-gini:0.29034\n",
      "[600]\tvalid-logloss:0.15462\tvalid-gini:0.29223\n",
      "[700]\tvalid-logloss:0.15458\tvalid-gini:0.29313\n",
      "[800]\tvalid-logloss:0.15455\tvalid-gini:0.29412\n",
      "[900]\tvalid-logloss:0.15453\tvalid-gini:0.29438\n",
      "[1000]\tvalid-logloss:0.15452\tvalid-gini:0.29502\n",
      "[1100]\tvalid-logloss:0.15451\tvalid-gini:0.29513\n",
      "[1200]\tvalid-logloss:0.15448\tvalid-gini:0.29535\n",
      "[1300]\tvalid-logloss:0.15449\tvalid-gini:0.29533\n",
      "[1400]\tvalid-logloss:0.15447\tvalid-gini:0.29586\n",
      "[1500]\tvalid-logloss:0.15446\tvalid-gini:0.29596\n",
      "[1600]\tvalid-logloss:0.15446\tvalid-gini:0.29603\n",
      "[1700]\tvalid-logloss:0.15445\tvalid-gini:0.29610\n",
      "[1800]\tvalid-logloss:0.15444\tvalid-gini:0.29622\n",
      "[1900]\tvalid-logloss:0.15445\tvalid-gini:0.29619\n",
      "[1999]\tvalid-logloss:0.15444\tvalid-gini:0.29641\n",
      "폴드 5  지니계수 : 0.2964012751575175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기 생성\n",
    "folds = StratifiedKFold(n_splits= 5 , shuffle= True , random_state= 1991)\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds = np.zeros(X.shape[0])\n",
    "\n",
    "# OOF 방식으로 훈련된 모델 훈련 , 검증 , 예측\n",
    "\n",
    "for idx , (train_idx , valid_idx) in enumerate(folds.split(X,y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "\n",
    "    print('#' *40,  f'폴드 {idx+1} / 폴드 {folds.n_splits}' , '#'*40)\n",
    "\n",
    "\n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train , y_train = X[train_idx] , y[train_idx]\n",
    "    X_valid , y_valid = X[valid_idx] , y[valid_idx]\n",
    "\n",
    "    #XGBoost 전용 데이터셋 생성\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train , y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid , y_valid)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    #XGBoost 모델 훈련\n",
    "    xgb_model = xgb.train(params = max_params,\n",
    "                          dtrain = dtrain,\n",
    "                          num_boost_round = 2000,\n",
    "                          evals = [(dvalid , 'valid')],\n",
    "                          maximize = True,\n",
    "                          feval = gini,\n",
    "                          early_stopping_rounds = 200,\n",
    "                          verbose_eval = 100)\n",
    "\n",
    "    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n",
    "    best_iter= xgb_model.best_iteration\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "\n",
    "    oof_test_preds += xgb_model.predict(dtest, iteration_range = (0 , best_iter))/ folds.n_splits\n",
    "\n",
    "    oof_test_preds_xgb = oof_test_preds\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
    "    oof_val_preds[valid_idx] += xgb_model.predict(dvalid , iteration_range=(0, best_iter))\n",
    "\n",
    "\n",
    "    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
    "    gini_score = eval_gini(y_valid , oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx+1}  지니계수 : {gini_score}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oof_val_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-90ae067261ef>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0moof_val_preds\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'oof_val_preds' is not defined"
     ]
    }
   ],
   "source": [
    "oof_val_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF 검증 데이터 지니계수 :  0.28905038063620453\n"
     ]
    }
   ],
   "source": [
    "print('OOF 검증 데이터 지니계수 : ' , eval_gini(y , oof_val_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 성능 개선 3 : LightGBM 과 XGBoost 앙상블"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "oof_test_preds = oof_test_preds_lgb *0.5 + oof_test_preds_xgb * 0.5\n",
    "\n",
    "\n",
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "           target\nid               \n0        0.069984\n1        0.055953\n2        0.059893\n3        0.036767\n4        0.092453\n...           ...\n1488022  0.210374\n1488023  0.108345\n1488024  0.084375\n1488025  0.050856\n1488026  0.075178\n\n[892816 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.069984</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.055953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.059893</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.036767</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.092453</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1488022</th>\n      <td>0.210374</td>\n    </tr>\n    <tr>\n      <th>1488023</th>\n      <td>0.108345</td>\n    </tr>\n    <tr>\n      <th>1488024</th>\n      <td>0.084375</td>\n    </tr>\n    <tr>\n      <th>1488025</th>\n      <td>0.050856</td>\n    </tr>\n    <tr>\n      <th>1488026</th>\n      <td>0.075178</td>\n    </tr>\n  </tbody>\n</table>\n<p>892816 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}